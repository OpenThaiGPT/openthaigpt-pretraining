{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOzQJUGCFNCPojmbzHpZ7jS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fkREVSTw0S1-","executionInfo":{"status":"ok","timestamp":1685902763798,"user_tz":-420,"elapsed":5752,"user":{"displayName":"Chawakorn Phiantham","userId":"05119468888744169723"}},"outputId":"58a1ce0f-a766-4213-a301-a245cef2a3e1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1OBbo21v_-esL31rxtNtsMHrA8T1JYqAd\n","To: /content/core.zip\n","100% 538M/538M [00:04<00:00, 108MB/s] \n"]}],"source":["!gdown 1OBbo21v_-esL31rxtNtsMHrA8T1JYqAd"]},{"cell_type":"code","source":["!unzip /content/core.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ALjpsLqf0c24","executionInfo":{"status":"ok","timestamp":1684783363926,"user_tz":-420,"elapsed":14218,"user":{"displayName":"Chawakorn Phiantham","userId":"05119468888744169723"}},"outputId":"e48418ec-bad9-4b46-b0aa-a0a60ffb1092"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/core.zip\n","replace th.sp.model? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: th.sp.model             \n","  inflating: th.sp.vocab             \n","  inflating: tmp_dataset.csv         \n","  inflating: decision_tree.sav       \n","  inflating: th.arpa.bin             \n"]}]},{"cell_type":"code","source":["!pip install kenlm"],"metadata":{"id":"QmepTY4d0uCA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"id":"PU08OQXn0-v6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import kenlm\n","import math\n","import numpy as np\n","import pickle\n","import scipy\n","import sentencepiece  # type: ignore\n","from text_normalizer import normalize\n","from typing import List\n","\n","\n","class SentencesLM:\n","    \"\"\"Returns the score of each individual paragraph.\"\"\"\n","\n","    def __init__(self):\n","        lm_config = kenlm.Config()\n","        lm_config.load_method = 2\n","\n","        lm_model_filename = \"th.arpa.bin\"\n","        self.lm = kenlm.Model(str(lm_model_filename), lm_config)\n","        self.sp = sentencepiece.SentencePieceProcessor()\n","        self.sp.load(\"th.sp.model\")\n","\n","    def pp(self, log_score, length) -> float:\n","        \"\"\"Compute perplexity score\"\"\"\n","        return 10.0 ** (-log_score / length)\n","\n","    def do(self, document) -> float:  # type: ignore\n","        \"\"\"Compute perplexity for each line of document\"\"\"\n","        total_pp = 0\n","        total_length = 0\n","        for line in document:\n","            line = normalize(line, accent=False)\n","            tokenized_line = \" \".join(self.sp.encode_as_pieces(line))\n","            log_score = self.lm.score(tokenized_line)\n","            length = len(line.split()) + 1\n","\n","            total_length += length\n","            total_pp += log_score\n","        return round(self.pp(total_pp, total_length), 1)\n","\n","\n","classifier_filename = \"decision_tree.sav\"\n","classifier = pickle.load(open(classifier_filename, \"rb\"))\n","\n","lm = SentencesLM()\n","\n","\n","def classify_spam(text: str):\n","    \"\"\"Classify if text is spam using perplexity and decision tree as thresholder\"\"\"\n","\n","    pp_score = lm.do(text.split(\"\\n\"))\n","\n","    log_pp_score = math.log(pp_score)\n","\n","    prediction = classifier.predict(np.array([log_pp_score]).reshape(1, 1))\n","\n","    return prediction, log_pp_score\n","\n","\n","def sample_score(log_scores, n, percentage=0.1) -> np.ndarray:\n","    np.random.seed(0)\n","\n","    lower_bound, upper_bound = min(log_scores), max(log_scores)\n","\n","    mean, std = np.mean(log_scores), np.std(log_scores)\n","\n","    sampled_scores = scipy.stats.truncnorm.rvs(\n","        (lower_bound - mean) / std,\n","        (upper_bound - mean) / std,\n","        loc=mean,\n","        scale=std,\n","        size=int(percentage * n),\n","    )\n","\n","    return sampled_scores\n","\n","\n","def sample_text_back(texts, log_scores, percentage=0.1, replace=True) -> List[str]:\n","    \"\"\"Sample some spam text back in the dataset\n","    using log score distribution of language model\"\"\"\n","\n","    sampled_scores = sample_score(log_scores, len(texts), percentage)\n","\n","    sampled_texts = []\n","\n","    selected_idx = set()\n","\n","    for samp_score in sampled_scores:\n","        min_diff, min_idx = float(\"inf\"), -1\n","\n","        for idx, s in enumerate(log_scores):\n","            if idx in selected_idx:\n","                continue\n","\n","            diff = (samp_score - s) ** 2\n","            if diff < min_diff:\n","                min_diff = diff\n","                min_idx = idx\n","\n","        sampled_texts.append(texts[min_idx])\n","\n","        if not replace:\n","            selected_idx.add(min_idx)\n","\n","    return sampled_texts\n"],"metadata":{"id":"Cflbmogv0sBd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute perplexity \n","lm.do([\"หนังxจีนมาใหม่ TM0165 แม่เลี้ยงสาวWang Xiaoni หลับอยู่ เจอลูกเลี้ยงชวนเพื่อนมารุมเย็ดแม่เลี้ยง จับมอมยาสลบก่อนลวนลามลงมืดข่มขืนxxx สวิง 3-1 เย็ดจนแตกในซะใจ\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xkktYQTU4Y_n","executionInfo":{"status":"ok","timestamp":1684782836220,"user_tz":-420,"elapsed":2,"user":{"displayName":"Chawakorn Phiantham","userId":"05119468888744169723"}},"outputId":"0e200f94-f25b-468d-8884-0be3466762eb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["40.69115244919519"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Classify spam \n","\n","classify_spam(\"หนังxจีนมาใหม่ TM0165 แม่เลี้ยงสาวWang Xiaoni หลับอยู่ เจอลูกเลี้ยงชวนเพื่อนมารุมเย็ดแม่เลี้ยง จับมอมยาสลบก่อนลวนลามลงมืดข่มขืนxxx สวิง 3-1 เย็ดจนแตกในซะใจ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxlZRRlJ34n5","executionInfo":{"status":"ok","timestamp":1684782756391,"user_tz":-420,"elapsed":320,"user":{"displayName":"Chawakorn Phiantham","userId":"05119468888744169723"}},"outputId":"145e54f0-2ee5-4f14-c486-3f262c83acf4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([1]), 40.69115244919519)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# sampled spam texts back 10% since we want model to know some of them\n","import pandas as pd\n","df = pd.read_csv(\"/content/tmp_dataset.csv\")\n","\n","texts = df[\"text\"]\n","log_scores = df[\"log_score\"]\n","sampled_texts = sample_text_back(texts,log_scores)\n","sampled_texts[:5]"],"metadata":{"id":"k7e4m0xj5h9o"},"execution_count":null,"outputs":[]}]}