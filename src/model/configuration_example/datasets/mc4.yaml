tokenized:
  path: None
  train_split: None
  eval_split: None
train:
  dataset_name: mc4
  split: train  # type: ignore
  shuffle: false
  buffer_size: 10000
  streaming: false
  from_disk: false
val:
  dataset_name: mc4
  split: validation  # type: ignore
  shuffle: false
  buffer_size: 10000
  streaming: false
  from_disk: false