output_path: "tokenizer"
vocab_size: 30000
streaming: True
load_dataset_path: oscar
load_dataset_name: unshuffled_deduplicated_th
load_dataset_local_path: None
load_dataset_data_type: None
large_corpus: false
mode: spm # spm | bpe
